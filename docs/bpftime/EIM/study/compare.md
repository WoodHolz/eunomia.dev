# Extension Systems compare with EIM

## 1. Case Studies of Extension Security Failures

**Overview:** Software *extensions* (plugins, add-ons, modules) greatly extend functionality but can introduce serious security risks if not tightly controlled. Historically, *loosely controlled extension models* have led to vulnerabilities like buffer overflows, sandbox escapes, and privilege escalations. Below, we examine notable incidents and how a stricter model (like **EIM** – an *Extension Isolation Mechanism*) could have mitigated them. A comparative table at the end of this section summarizes these cases and EIM’s potential impact.

### 1.1 Buffer Overflow Vulnerabilities in Extensions

- **ActiveX Controls (Internet Explorer):** Microsoft’s ActiveX allowed native code extensions in the browser with minimal restriction. Many ActiveX controls were marked “safe for scripting” (accessible to websites) and contained memory safety bugs. For example, the Windows Troubleshooter ActiveX control had a *buffer overflow* that let attackers execute arbitrary code by luring a user to a malicious web page ([Microsoft Security Bulletin MS03-042 - Critical | Microsoft Learn](https://learn.microsoft.com/en-us/security-updates/securitybulletins/2003/ms03-042#:~:text=A%20security%20vulnerability%20exists%20in,The%20Microsoft)). Because ActiveX had full system access, exploiting this overflow gave the attacker the user’s privileges (or higher, if the user was admin). This lack of memory safety and sandboxing made ActiveX extensions notorious for remote code execution (RCE) exploits.

- **Adobe Acrobat Reader Plug-ins:** Early browser plug-in models (NPAPI) similarly allowed native code with full privileges. Incidents like the *Adobe Acrobat ActiveX Buffer Overflow* (CVE-2007-5659) let malicious PDFs trigger an overflow in a browser plug-in, leading to code execution ([IBM Tivoli ActiveX Buffer Overflow (April 20, 2012) - SonicWall](https://www.sonicwall.com/blog/ibm-tivoli-activex-buffer-overflow-april-20-2012#:~:text=IBM%20Tivoli%20ActiveX%20Buffer%20Overflow,In%20order%20to)) ([Yahoo! Audio Conferencing ActiveX control vulnerable to buffer ...](https://www.kb.cert.org/vuls/id/272644#:~:text=Yahoo%21%20Audio%20Conferencing%20ActiveX%20control,Yahoo%21%20Audio%20Conferencing%20ActiveX%20control)). These cases highlight how **memory unsafe extension interfaces** can be a direct vector for attackers.

- **Mitigation with EIM:** An EIM would enforce memory safety for extensions – for instance, by requiring extensions to run in a memory-safe sandbox or language. Buffer overflow exploits as seen in ActiveX would be prevented at the root: the extension code either couldn’t allocate arbitrary memory or would be confined to a sandbox that traps on overflow. For example, EIM might mandate bounds-checked memory access (as WebAssembly does) so an overflow would not corrupt the host’s memory ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=Each%20WebAssembly%20module%20executes%20within,This%20implies)) ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=Modules%20must%20declare%20all%20accessible,from%20control%20flow%20hijacking%20attacks)). In the ActiveX case, EIM could have required the control to run in a restricted environment with no direct pointer access, averting arbitrary code execution.

### 1.2 Sandbox Escape Incidents

- **Browser Sandboxes (Chrome V8):** Modern browsers isolate extension or webpage code in sandboxed processes. However, sandbox *escape* vulnerabilities still occur when the isolation is not airtight. A recent Chrome zero-day (CVE-2024-4761) was a **V8 engine out-of-bounds write** bug that allowed code running in a Chrome renderer process to break out of the sandbox and execute with higher privileges ([Dangerous Google Chrome Zero-Day Allows Sandbox Escape](https://www.darkreading.com/vulnerabilities-threats/dangerous-google-chrome-zero-day-sandbox-escape#:~:text=The%20latest%20update%2C%20to%20version,via%20a%20crafted%20HTML%20page)). In this case, an attacker first exploits a memory bug in the extension/webpage context, then uses it to escape the sandbox (pivoting from the confined renderer process to the broader system). This kind of two-step exploit (renderer compromise → sandbox escape) is common in Chrome attack chains ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=Unfortunately%2C%20threat%20actors%20routinely%20attack,need%20multiple%20layers%20of%20protection)) ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=The%20Limits%20of%20Process%20Sandboxing)).

- **DevTools Extension Escape:** In one reported case, a vulnerability in Chrome’s DevTools and extension interaction (CVE-2024-5836) allowed an installed *extension to escape Chrome’s sandbox* by opening a crafted link ([Escaping the Chrome Sandbox Through DevTools - ading2210](https://ading.dev/blog/posts/chrome_sandbox_escape.html#:~:text=Escaping%20the%20Chrome%20Sandbox%20Through,escape%20from%20a%20browser%20extension)). Similarly, Firefox’s content sandbox has been bypassed in the past by chaining browser engine bugs with extension capabilities.

- **VS Code Extensions (Webview Escape):** Extensions are not limited to browsers. In 2022, VS Code (which allows third-party extensions) had a misconfiguration in how extension *Webviews* were sandboxed. One extension’s XSS bug allowed malicious HTML to break out of the Webview sandbox and execute code in the extension’s context ([Escaping misconfigured VSCode extensions - The Trail of Bits Blog](https://blog.trailofbits.com/2023/02/21/vscode-extension-escape-vulnerability/#:~:text=Why%20should%20you%20care%20about,is%20running%20in%20the%20background)) ([Escaping misconfigured VSCode extensions - The Trail of Bits Blog](https://blog.trailofbits.com/2023/02/21/vscode-extension-escape-vulnerability/#:~:text=VSCode%20Webviews)). Because VS Code extensions run with the user’s full privileges (able to read files and run shell commands ([Escaping misconfigured VSCode extensions - The Trail of Bits Blog](https://blog.trailofbits.com/2023/02/21/vscode-extension-escape-vulnerability/#:~:text=Before%20diving%20into%20the%20bugs%2C,full%20compromise%20of%20the%20system))), this meant an attacker controlling a Webview could potentially **steal local files (even SSH keys)** or run arbitrary commands by exploiting the extension vulnerability ([Escaping misconfigured VSCode extensions - The Trail of Bits Blog](https://blog.trailofbits.com/2023/02/21/vscode-extension-escape-vulnerability/#:~:text=Why%20should%20you%20care%20about,is%20running%20in%20the%20background)).

- **Mitigation with EIM:** EIM would maintain a *robust sandbox barrier* around extension code. In the Chrome V8 case, EIM could have added an extra layer of isolation – for example, running extension code in a memory-safe intermediate representation (like WASM) with explicit bounds checks, so even a V8 bug couldn’t directly breach the process’s memory. EIM might also employ **multiple enforcement layers** (language safety, process isolation, and OS-level sandboxing) so that a single engine flaw is not enough to escape. In the VS Code scenario, EIM could ensure that even if an extension’s UI (Webview) is compromised, the core extension logic is running with *least privilege* – e.g., file system access only via vetted APIs, preventing an easy jump from a UI XSS to full file access. Additionally, EIM could require that extensions which render untrusted content (like the Webview) run in a *separate, locked-down process* or **sandbox compartment**, making it far harder for a Webview exploit to impact the host system.

### 1.3 Privilege Escalation through Extensions

- **Legacy Firefox Extensions (Full Privileges):** Firefox’s old XUL extension framework (pre-2017) granted installed add-ons *unrestricted privileges* in the browser process – they could read/write files, execute programs, etc. ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Mozilla%20Firefox%20introduced%20the%20first,Once%20a%20vulnerability%20is)). This meant any vulnerability in an extension’s script (or a malicious extension) could escalate to full host privileges. Attackers demonstrated this at DEFCON 2009 by exploiting popular Firefox add-ons to **execute native code and install malware** ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=complete%20browser%20privileges%2C%20including%20full,a%20number%20of%20popular%20Firefox)). Essentially, Firefox’s extensions acted with the user’s authority without isolation – a design now recognized as highly insecure.

- **Chrome Extension Vulnerabilities:** Chrome’s extension model is more restrictive, but **over-privileged extensions** or logic flaws can still lead to escalation. A notable incident was the AVG “Web TuneUp” Chrome extension (installed by an antivirus program) which had *multiple critical bugs*. It injected insecure scripts into web pages and exposed APIs such that any website could steal browsing history and cookies, or even inject arbitrary scripts into all pages the user visited ([Google probes AVG Chrome widget after 9m users exposed by bugs • The Register](https://www.theregister.com/2015/12/29/avg_google_chrome_extension/#:~:text=According%20to%20Ormandy%2C%20the%20extension,hijack%20the%20victim%27s%20webmail%20inbox)) ([Google probes AVG Chrome widget after 9m users exposed by bugs • The Register](https://www.theregister.com/2015/12/29/avg_google_chrome_extension/#:~:text=And%2C%20we%27re%20told%2C%20man,rendering%20any%20SSL%20encryption%20useless)). Essentially, a malicious webpage could escalate its privileges by leveraging this overly-powerful extension (gaining access to other sites like the user’s email).

- **Kernel Extensions (eBPF):** At the OS level, *eBPF* provides a way to load extensions into the Linux kernel (for networking, tracing, etc.) with supposed safety checks. But flaws in the eBPF verifier have led to **privilege escalations** – letting an unprivileged user gain kernel (root) execution. For example, CVE-2023-2163 (a bug in Linux eBPF) was shown to allow a “small bug to compromise the entire system” ([Understanding the Security Aspects of Linux eBPF - Pentera](https://pentera.io/blog/the-good-bad-and-compromisable-aspects-of-linux-ebpf/#:~:text=fairly%20small%20bug%20can%20lead,compromise%20of%20the%20entire%20system)). In general, eBPF bugs that bypass its checks give an attacker a path to run arbitrary code in the kernel, a severe privilege escalation ([Understanding the Security Aspects of Linux eBPF - Pentera](https://pentera.io/blog/the-good-bad-and-compromisable-aspects-of-linux-ebpf/#:~:text=eBBF%20is%20a%20two,review%20how%20it%20is%20done)).

- **Mitigation with EIM:** EIM is designed around the *principle of least privilege*. In a browser context, EIM would require that extensions declare and be limited to the minimal permissions they need – similar to Chrome’s Manifest V3 approach, but potentially even more fine-grained and enforced by the runtime. For instance, an EIM-governed browser extension couldn’t arbitrarily inject scripts into every page or read all browsing data unless explicitly allowed, which would have contained the AVG extension’s impact. (Chrome’s newer model in fact blocks remote code and excessive privileges ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=Request%20minimal%20permissions)) ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=This%20extension%20in%20the%20sample,https%3A%2F%2Fmalicious_website.com)), aligning with what EIM would enforce.) In the case of kernel extensions like eBPF, EIM would add **defense-in-depth**: even if the verifier has a bug, the extension code might still be running in a secondary sandbox or constrained environment (e.g., user-space eBPF JIT with hardware keys isolation) to prevent total kernel compromise. In short, EIM would assume any single layer can fail, and thus use layered isolation and strict privilege gating to avert escalation.

### 1.4 Comparative Table: Incidents vs. EIM Mitigations

| **Security Failure (Extension)**                                      | **Root Cause**                                | **Impact**                                      | **How EIM Could Mitigate**                                  |
|-----------------------------------------------------------------------|-----------------------------------------------|-------------------------------------------------|------------------------------------------------------------|
| **ActiveX buffer overflow** (IE, 2003) ([Microsoft Security Bulletin MS03-042 - Critical | Microsoft Learn](https://learn.microsoft.com/en-us/security-updates/securitybulletins/2003/ms03-042#:~:text=A%20security%20vulnerability%20exists%20in,The%20Microsoft))      | Native extension with no memory safety; marked “safe for scripting” | Remote code execution on host via overflow exploit | *Memory-safe sandbox:* EIM would sandbox extensions in memory-safe code (preventing overflows). Even if exploited, code runs in a contained environment, not with full host access. |
| **Firefox XUL Add-ons** (pre-2011) ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Mozilla%20Firefox%20introduced%20the%20first,Once%20a%20vulnerability%20is))           | Extensions had full OS/browser privileges (no isolation or permission model) | Extension malware or exploited bug can control browser and OS files | *Least privilege enforcement:* EIM mandates that extensions get only minimal permissions (e.g. no file access unless needed). Host APIs are gated, so even a compromised extension can’t exceed its small allowance. |
| **Chrome extension (AVG Web TuneUp)** (2015) ([Google probes AVG Chrome widget after 9m users exposed by bugs • The Register](https://www.theregister.com/2015/12/29/avg_google_chrome_extension/#:~:text=According%20to%20Ormandy%2C%20the%20extension,hijack%20the%20victim%27s%20webmail%20inbox)) | Overly broad privileges and insecure API injection by extension | Any website could hijack user sessions, steal data, run scripts via the extension | *Privilege partitioning:* Under EIM, such an extension would be confined to specific contexts. EIM’s policy would prevent an extension from exposing dangerous APIs to untrusted web content, and limit its access to sensitive data by default. |
| **Chrome V8 sandbox escape** (CVE-2024-4761) ([Dangerous Google Chrome Zero-Day Allows Sandbox Escape](https://www.darkreading.com/vulnerabilities-threats/dangerous-google-chrome-zero-day-sandbox-escape#:~:text=The%20latest%20update%2C%20to%20version,via%20a%20crafted%20HTML%20page)) | Memory error in extension/web content engine + single-process sandbox design | Sandboxed code escapes to execute with browser or OS privileges (potential full compromise) | *Strong multi-layer sandbox:* EIM would use layered isolation (e.g. in-process SFI **and** OS process isolation). A memory bug wouldn’t immediately allow escape because the extension code might be further constrained by EIM’s runtime checks (e.g. no arbitrary jumps, as in WASM ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=Modules%20must%20declare%20all%20accessible,from%20control%20flow%20hijacking%20attacks))). Even if one layer is breached, another stops the attacker. |
| **Linux eBPF exploit** (kernel ext, 2022) ([Understanding the Security Aspects of Linux eBPF - Pentera](https://pentera.io/blog/the-good-bad-and-compromisable-aspects-of-linux-ebpf/#:~:text=eBBF%20is%20a%20two,review%20how%20it%20is%20done))    | Bug in verifier of allowed extension code (insufficient control) | Local priv. escalation – unprivileged user executes code in kernel | *Rigorous verification & isolation:* EIM would supplement kernel verifier with formal proofs or run extension in user-space with limited kernel hooks. Even if extension code has a bug, it can’t directly write to arbitrary kernel memory. EIM could, for example, run eBPF programs in a **user-space sandbox** and only allow safe interactions with kernel, preventing a runaway exploit. |

**Sources:** The above incidents draw from documented vulnerabilities and reports ([Microsoft Security Bulletin MS03-042 - Critical | Microsoft Learn](https://learn.microsoft.com/en-us/security-updates/securitybulletins/2003/ms03-042#:~:text=A%20security%20vulnerability%20exists%20in,The%20Microsoft)) ([Google probes AVG Chrome widget after 9m users exposed by bugs • The Register](https://www.theregister.com/2015/12/29/avg_google_chrome_extension/#:~:text=According%20to%20Ormandy%2C%20the%20extension,hijack%20the%20victim%27s%20webmail%20inbox)) ([Dangerous Google Chrome Zero-Day Allows Sandbox Escape](https://www.darkreading.com/vulnerabilities-threats/dangerous-google-chrome-zero-day-sandbox-escape#:~:text=The%20latest%20update%2C%20to%20version,via%20a%20crafted%20HTML%20page)) ([Understanding the Security Aspects of Linux eBPF - Pentera](https://pentera.io/blog/the-good-bad-and-compromisable-aspects-of-linux-ebpf/#:~:text=eBBF%20is%20a%20two,review%20how%20it%20is%20done)) ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Mozilla%20Firefox%20introduced%20the%20first,Once%20a%20vulnerability%20is)). They illustrate recurring weaknesses when extension models lack strong isolation. EIM’s approach – combining memory safety, strict sandboxing, and least-privilege policies – directly addresses these weaknesses by design.

## 2. Similar Sandboxing and Privilege-Reduction Approaches (Beyond eBPF & WASM)

To better understand EIM in context, we compare it to existing technologies aimed at securely running extension or plug-in code. Two prominent modern examples are **eBPF** (for kernel extensions) and **WebAssembly (WASM)** (for safe web/app modules), which both strive to execute untrusted code safely. EIM shares goals with these but also with a number of other approaches. Below we examine similar models – RLBox, NaCl, ERIM, and more – highlighting their security benefits and performance trade-offs, and comparing them to what EIM promises.

### 2.1 RLBox – Fine-Grained In-Process Sandboxing

**RLBox** is a framework (used in Firefox) that isolates third-party libraries by compiling them to WebAssembly and then back to native code, creating an in-process sandbox ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=Isolating%20with%20RLBox)) ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=However%2C%20the%20transformation%20places%20two,easy%20with%20a%20tainting%20layer)). The sandboxed code cannot jump to arbitrary addresses in the host application or access memory outside its assigned region ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=However%2C%20the%20transformation%20places%20two,easy%20with%20a%20tainting%20layer)). This effectively enforces *software-based fault isolation (SFI)* within the same process. 

- **Security:** By restricting control flow and memory range, RLBox contains any memory corruption within the sandboxed library, preventing it from hijacking the host application. Even if a vulnerability exists in, say, an image decoding library, an attacker can’t use it to execute code in the browser’s context – they’d be trapped in the WebAssembly sandbox. Mozilla noted that a zero-day in an isolated library should pose *“no threat to Firefox”* – researchers would be rewarded for a sandbox *bypass* rather than a library exploit ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=Going%20forward%2C%20we%20can%20treat,vulnerability%20in%20the%20isolated%20library)). This layered approach (library isolation on top of process sandboxing) greatly hardens security.

- **Performance:** A key advantage of RLBox is *low overhead*. Because the sandboxed code runs in the same process (just with checks on calls and memory), it avoids expensive context switches into a separate process. The designers report **modest, transient overhead** – only minor page load latency impacts even when sandboxing performance-sensitive libraries like image and video decoders ([Retrofitting Fine Grain Isolation in the Firefox Renderer | USENIX](https://www.usenix.org/conference/usenixsecurity20/presentation/narayan#:~:text=RLBox%20supports%20efficient%20sandboxing%20through,and%20the%20zlib%20decompression%20library)) ([Retrofitting Fine Grain Isolation in the Firefox Renderer | USENIX](https://www.usenix.org/conference/usenixsecurity20/presentation/narayan#:~:text=isolation%20or%20multi,and%20the%20zlib%20decompression%20library)). Techniques like ahead-of-time WASM compilation and even cross-boundary inlining are used to optimize performance ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=Clang%20to%20compile%20Firefox%2C%20and,existing%20build%20system%20could%20ingest)). Thus, RLBox achieves strong isolation with minimal slowdown (on the order of a few percent overhead in Firefox’s real-world usage).

- **Flexibility:** RLBox can be incrementally applied to individual components without a full app rewrite. It integrates via a *tainting API* in C++ to ensure all data coming out of the sandbox is checked or copied safely ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=stack%20arxiv,easy%20with%20a%20tainting%20layer)). However, it’s currently specialized for isolating known subcomponents (not arbitrary user-installed extensions). EIM could be seen as a generalized version of this concept, potentially allowing **any** extension code to be isolated similarly. Where RLBox requires the host developer to decide which library to sandbox, EIM might automatically sandbox all third-party extension code by default.

**Comparison to EIM:** EIM and RLBox share the idea of *in-process isolation.* If EIM uses a WebAssembly or SFI-based sandbox for extensions, it would be analogous to how RLBox sandboxes libraries. Both aim for security with low overhead. The difference is scope: RLBox is a targeted mechanism (Firefox uses it for specific libraries like Graphite, Hunspell, etc.), whereas EIM is envisioned as a *universal model for extensions*. EIM might generalize RLBox’s approach to any plugin or extension code, providing a framework to confine that code similarly (with control-flow integrity and memory safety checks). In terms of performance and flexibility, EIM would strive for RLBox’s lightweight overhead, but with a system that extension developers can plug into without needing deep browser integration code – effectively making safe extension isolation a built-in feature.

### 2.2 Google Native Client (NaCl) and Portable NaCl (PNaCl)

**Native Client (NaCl)** was Google’s pioneering sandbox for running native code (C/C++ compiled) in the browser. It used *static analysis and sandboxing* to allow modules of x86 or ARM machine code to run at near-native speed, but constrained by a verifier to prevent unsafe operations ([Google Native Client - Wikipedia](https://en.wikipedia.org/wiki/Google_Native_Client#:~:text=Google%20Native%20Client%20,3)). NaCl essentially applied **software fault isolation** at the binary level: it validated instruction sequences (e.g., ensuring no jump could exit a sandboxed memory region, no system calls executed directly, etc.), and executed the code in a restricted process. PNaCl later introduced a portable bitcode format (LLVM IR) to allow architecture-independent binaries ([Google Native Client - Wikipedia](https://en.wikipedia.org/wiki/Google_Native_Client#:~:text=Portable%20Native%20Client%20,this%20issue%20by%20using%20sandboxing)).

- **Security:** NaCl’s security model was much stricter than earlier native extension tech like ActiveX. The Wikipedia summary notes that *ActiveX had full access to the system*, whereas *Native Client avoids this issue by using sandboxing* ([Google Native Client - Wikipedia](https://en.wikipedia.org/wiki/Google_Native_Client#:~:text=has%20been%20implemented%20before%20in,this%20issue%20by%20using%20sandboxing)). The NaCl sandbox had **granular control**: it restricted memory accesses (segmenting memory so the code can’t touch the browser’s memory) and required all system interactions to go through a broker (the Pepper API). This meant even if a NaCl module had a buffer overflow, at worst it could crash or misbehave inside the sandbox; it shouldn’t execute arbitrary OS calls or read/write outside its sandbox memory. NaCl successfully blocked many traditional exploits by design.

- **Performance:** A major goal of NaCl was *speed* – achieving near-native execution. In practice, NaCl introduced some overhead due to alignment rules and guard instructions, but it was quite efficient (reports indicated within ~5% of native performance for computation-heavy code) ([[PDF] Native Client: A Sandbox for Portable, Untrusted x86 Native Code](https://research.google.com/pubs/archive/34913.pdf#:~:text=Native%20Client%20aims%20to%20give,Native%20Client%20uses)). It leveraged the CPU’s hardware features (segmentation on x86, for example) to enforce memory confines cheaply. PNaCl added a translation step but still focused on efficiency. The trade-off was the complexity of the compiler and verification toolchain, not so much runtime speed.

- **Flexibility:** NaCl required extensions to be specifically compiled for it, and developers had to use Chrome’s Pepper APIs for any interaction (like graphics, input, networking). This was a hurdle; it wasn’t just arbitrary native code – it had to be adapted. Ultimately, NaCl fell out of favor as WebAssembly emerged, because WASM provided similar speed and safety but with a more standard Web platform approach. NaCl also was Chrome-specific. 

**Comparison to EIM:** EIM could be thought of as a successor in spirit to NaCl, but more universal. Where NaCl focused on *browser plugins*, EIM might apply to any software extension (browser, app, OS module) using modern techniques. EIM would likely not require a custom CPU-specific sandbox like NaCl did, but could leverage WebAssembly or hardware features (like MPK, see below) to isolate code. In terms of **effectiveness**, NaCl proved it’s possible to run native-speed code safely – EIM would aim for the same, using updated technology. For **flexibility**, EIM might prefer WebAssembly as the input (since any language can compile to WASM), rather than native ISA binaries, to avoid the portability issues NaCl had. The performance of EIM could be comparable to NaCl or better if using hardware support; the overhead should be low enough for real-time use (NaCl’s near-native performance is a benchmark to meet). In summary, EIM can be seen as adopting NaCl’s *sandboxing rigor* (no uncontrolled syscalls or memory access) but with more openness (not tied to Chrome only) and ease of use (leveraging standards and possibly dynamic translation for extensions). 

### 2.3 ERIM – In-Process Isolation with Memory Protection Keys

**ERIM** (Secure, Efficient In-process Isolation with Protection Keys) is a research project that isolates components within a single process using Intel’s Memory Protection Keys (MPK) hardware feature ([ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK) | USENIX](https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner#:~:text=In%20this%20paper%2C%20we%20present,at%20high%20domain%20switching%20rates)). The key idea is to split the address space into domains (e.g., “trusted” and “untrusted” parts) and use CPU-enforced keys to restrict memory access when switching between domains, without going to the kernel for context switch. ERIM also uses a binary inspector to ensure untrusted code can’t circumvent the restrictions (e.g., by issuing an MPK reconfiguration) ([ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK) | USENIX](https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner#:~:text=In%20this%20paper%2C%20we%20present,at%20high%20domain%20switching%20rates)).

- **Security:** ERIM provides hardware-backed memory isolation. For example, an extension (untrusted module) could be in one domain and the host in another. When the extension runs, it cannot read or write the host’s memory (the hardware will block it if it tries), and vice versa. This is somewhat similar to SFI, but enforced by the CPU’s memory management unit rather than instruction-level instrumentation. By inspecting the binary, ERIM ensures the untrusted module doesn’t contain forbidden instructions that could disable the protection keys. This means even a memory corruption in the extension can’t break into the host memory – it would hit a wall enforced at hardware speed. It’s a strong safety property, though currently it primarily protects memory (control-flow isolation still relies on not jumping into the middle of host code, which binary inspection also guards).

- **Performance:** ERIM’s big advantage is very low overhead context switching. Switching protection domains is done entirely in userspace by updating a thread-local protection key register, which is extremely fast (much faster than a full process context switch or even a syscall). The authors measured **<1% overhead** for as many as 100,000 domain switches per second ([ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK) | USENIX](https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner#:~:text=In%20this%20paper%2C%20we%20present,at%20high%20domain%20switching%20rates)) – essentially negligible performance cost for most applications. This makes ERIM attractive for fine-grained isolation (you could call into untrusted code frequently without a big slowdown). Traditional process isolation, by contrast, would choke on 100k context switches/sec. ERIM does have some fixed overhead in memory usage (each domain needs separate memory regions) and requires CPU support (Intel MPK available on relatively recent CPUs).

- **Flexibility:** ERIM doesn’t require special compilers or languages; it works at binary level with some constraints. It can be applied to existing applications with some modifications to designate isolated modules and replace unsafe instructions. However, it’s currently x86-specific (MPK). For extension systems, using ERIM would mean the host application and extension run in one process but different memory domains. That’s feasible for things like plugin architectures or even browser extensions, provided the runtime can manage the domains. One limitation: all code is still in one process space, so OS-level privileges are the same (if the process is compromised in another way, OS still sees it as one process). But the internal isolation is strong.

**Comparison to EIM:** If EIM is implemented at a low level, it could leverage technologies like ERIM. For instance, EIM could say: “When an extension is loaded, it will be placed in an MPK-isolated domain separate from the host.” This would give EIM hardware-enforced safety with minimal overhead – aligning with the goal of not sacrificing performance for security. Effectiveness-wise, ERIM’s approach means even high-frequency interactions between extension and host are safe and fast. EIM can combine this with other measures: memory keys protect memory, but EIM might also impose system call filters or permission checks (ERIM doesn’t inherently limit syscalls from the isolated code – that would need seccomp or other measures in tandem). So EIM could use ERIM for memory isolation and an API call monitor for controlling what the extension can do (thus covering both memory safety and privilege limitation). In terms of flexibility, ERIM shows it’s possible to isolate components without rewriting them in a new language – an extension in native code could be isolated if the platform enforces it with MPK. EIM might abstract that complexity away so extension developers don’t need to know about MPK – it just happens under the hood. The overhead of EIM in such a case would be similar to ERIM’s (<1%), making it extremely appealing: *strong isolation with essentially no user-visible performance impact* ([ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK) | USENIX](https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner#:~:text=In%20this%20paper%2C%20we%20present,at%20high%20domain%20switching%20rates)). The main trade-off is the requirement of specific hardware features (on CPUs that support it). EIM might need to fall back to software isolation on other platforms (like using SFI/WASM on ARM where MPK is not available). 

### 2.4 Other Sandbox and Privilege-Reduction Techniques

Beyond the three highlighted, there are other notable approaches that aim to securely run untrusted extensions or reduce their privileges:

- **Language-Based Isolation:** Some systems choose a safe language for extensions. For example, browser extensions in Chrome/Firefox are written in JavaScript/TypeScript (memory-safe languages) rather than C++, which inherently avoids buffer overflow issues. Similarly, sandboxing via *type safety* is used in systems like the JVM or .NET CLR for plugins. The upside is safety is ensured by the language runtime (no arbitrary pointer manipulation); the downside is that logic errors or abuses of provided APIs can still cause harm. EIM could incorporate this by *requiring extensions to be written in or compiled to a memory-safe language (like WASM, which is designed to be memory-safe and sandboxed)*. Memory-safe languages alone don’t enforce least privilege, so additional measures are needed for full security.

- **Process Sandboxing and OS Isolation:** Chrome’s multi-process architecture is a prime example – each web site and extension can run in a separate OS process under a restrictive sandbox (using job objects on Windows, seccomp-bpf on Linux, etc.). This greatly limits the damage if one component is compromised. The cost is higher memory usage and some performance overhead in cross-process communication. Another example is **hardware virtualization or containers**: An extreme but secure route is to run extensions in lightweight VMs or containers (like how some IDEs run plugins in separate containerized processes). This provides strong isolation (almost like a separate machine for the extension), but can be heavyweight. EIM would seek a middle ground: achieve *process-like* isolation strength at much lower cost (similar to how RLBox/ERIM do within one process). However, EIM can still leverage OS features – for instance, using separate processes for extensions where appropriate, combined with OS sandboxing (Seccomp, discussed later) to confine them. The model should be flexible: if an extension is large or untrusted, the system might decide to fork it out as a process under strict controls; if it’s small, maybe an in-process sandbox suffices. EIM’s framework could orchestrate this decision transparently.

- **Software Fault Isolation (SFI):** This is a classic technique underlying several of the above (NaCl, RLBox). Pure SFI (as in the research by Wahbe et al.) inserts checks around memory accesses and jumps in the untrusted code to ensure it stays in its sandbox. Modern incarnations like **WebAssembly** implement SFI at the bytecode level (with structured control flow and explicit bounds checks) ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=Modules%20must%20declare%20all%20accessible,from%20control%20flow%20hijacking%20attacks)) ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=,destinations%20within%20the%20enclosing%20function)). Another system, **XFI** (eXtensible Firmware Interface’s policy or eXecutable-only memory enforcement), was a research prototype that added inline reference monitors for security-critical operations. The *trade-off* for SFI is typically some performance cost (due to added checks) but no need for special hardware. For example, WebAssembly adds bounds-checking on every memory access (unless mitigated by techniques like hardware memory tagging in the future). This can be a few percent overhead in execution speed, but generally acceptable for the safety gained. EIM could use SFI (via WebAssembly or a similar bytecode) as a universal approach since it’s hardware-agnostic. The *overhead* is usually lower than heavy virtualization but higher than hardware MPK (since MPK has near-zero overhead). Combining SFI with JIT/AOT optimization and other tricks (as Firefox does with wasm2c in RLBox ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=Clang%20to%20compile%20Firefox%2C%20and,existing%20build%20system%20could%20ingest))) can reduce the performance hit significantly. 

- **Native OS Sandboxing APIs:** There are also OS-level frameworks like **Windows AppContainer** or **Android’s isolated processes** for apps, which could be analogized to extensions. For instance, a browser extension in Edge could run as a UWP AppContainer with a capability list. These limit accessible resources but are not commonly used for browser add-ons yet. EIM could potentially leverage such OS features when available (running each extension as a locked-down OS-level app). However, doing so for each small extension might be too heavy, which is why EIM would likely combine processes for coarse isolation and in-process sandboxing for fine-grained safety.

**Summary of Trade-offs:** All these approaches attempt to balance **security vs. performance vs. flexibility**:

- Approaches like separate processes or VMs give strong security (clear isolation boundaries) but with higher overhead (context switching, memory) and complexity (communication between host and extension).
- Approaches like in-process SFI or MPK (RLBox, ERIM) give fine-grained security with low overhead, but require careful design to ensure completeness of isolation (need to prevent any “backdoors” like stray function pointers or CPU instructions that break out).
- Language-based safety removes whole classes of bugs (like buffer overruns) but doesn’t inherently sandbox the code’s behavior (it could still call unsafe host APIs if allowed). 

**EIM’s Position:** The Extension Isolation Mechanism would likely combine these techniques to get the best of each. It might use *language-based SFI (WASM)* as a baseline so extensions can’t mismanage memory, use *OS sandboxing* as a guardrail (each extension might be in a process or at least subject to OS syscall filters), and possibly exploit *hardware features like MPK* when available to reduce overhead. In terms of effectiveness, EIM aims to **match or exceed** the security of these models – meaning an extension under EIM should be at least as contained as under NaCl or RLBox. In terms of flexibility, EIM should allow a wide range of extension logic (not just specific libraries or code compiled in special ways) – more like how WebAssembly can accept many languages. And regarding overhead, EIM aspires to be lightweight enough that users don’t notice a performance difference, comparable to RLBox’s and ERIM’s sub-5% overhead or NaCl’s near-native speed ([Retrofitting Fine Grain Isolation in the Firefox Renderer | USENIX](https://www.usenix.org/conference/usenixsecurity20/presentation/narayan#:~:text=RLBox%20supports%20efficient%20sandboxing%20through,and%20the%20zlib%20decompression%20library)) ([ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK) | USENIX](https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner#:~:text=In%20this%20paper%2C%20we%20present,at%20high%20domain%20switching%20rates)).

## 3. Prior Art and Literature on Extension Security Models

Securing extension systems has been a focus of both academic research and industry engineering for over a decade. Here we review some key prior art – including *browser extension least-privilege frameworks and OS-level security models* – and compare them to EIM. The goal is to see how EIM aligns with the principle of **least privilege**, and how it addresses gaps not fully solved by earlier models. We also provide references from papers and reports to contextualize EIM among existing security frameworks.

### 3.1 Least Privilege in Browser Extensions (Chrome Manifest v3, Firefox WebExtensions)

Browser vendors have learned the hard way that extensions must be restricted. Early Firefox extensions were essentially *unrestricted chrome code* running in the browser process ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Mozilla%20Firefox%20introduced%20the%20first,Once%20a%20vulnerability%20is)), which, as discussed, led to multiple security issues. The principle of **least privilege** says an extension should only have the permissions absolutely necessary for its function – nothing more – so that even if it is malicious or exploited, the damage is limited.

- **Firefox’s evolution:** Research by Adrienne Porter Felt in 2010 showed that 88% of studied Firefox add-ons didn’t need the powerful privileges they were given ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Firefox%20extensions,extension%20system%2C%20which%20supports%20restrictions)). Many add-ons could work with far fewer rights if the system allowed it. This study directly influenced extension reform. Firefox eventually moved to the **WebExtensions** model (around 2017), aligning with Chrome’s model. Under WebExtensions, Firefox extensions are written in JS and have a defined set of APIs and permission prompts, rather than unlimited XPCOM access. This significantly improved the security posture by removing the old XUL add-ons’ capability to, say, delete arbitrary files or launch processes unless explicitly allowed by a specific API.

- **Chrome’s extension model:** From its inception, Chrome designed extensions with a permission system and sandboxing. Each extension runs in a separate process (or several processes for background and content scripts) with restricted privileges. Extensions must declare in their manifest which host permissions (which websites) and which special APIs (e.g. tabs, storage, etc.) they need. The user has to approve these at install time. Chrome’s **Manifest V3**, introduced recently, tightens this further. It *forbids remotely hosted code* and disallows `eval()` or new script generation by extensions ([Improve extension security  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/migrate/improve-security#:~:text=Remove%20execution%20of%20arbitrary%20strings)) ([Improve extension security  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/migrate/improve-security#:~:text=Remove%20remotely%20hosted%20code)). All extension code must be included in the extension package and go through Chrome’s review (for store extensions). This prevents a huge class of attacks where an extension might fetch and execute unknown code at runtime. Manifest V3 also enforces more granular host permissions: an extension can prompt the user at runtime for access to a site, rather than grabbing blanket access to “<all_urls>”. Chrome explicitly encourages developers to **request minimal permissions** in the manifest ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=Request%20minimal%20permissions)), noting that limiting privileges also limits what an attacker can do if the extension is compromised ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=The%20Chrome%20browser%20limits%20an,and%20websites%20they%20depend%20on)) ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=This%20extension%20in%20the%20sample,https%3A%2F%2Fmalicious_website.com)). 

- **Examples of least privilege:** In practice, if an extension only needs to manipulate data on *example.com*, it should not ask for access to every site. Chrome’s model makes this possible (fine-grained host permissions). Firefox’s WebExtensions follow a similar approach; the same extension manifest can specify permissions and will be honored by Firefox. Additionally, both browsers now mandate that extensions be distributed with a digital signature (for integrity) and can be automatically disabled if malware is detected in them via updates. While signature is not “least privilege” per se, it complements the security model by ensuring only reviewed code runs.

**How EIM Compares:** EIM would incorporate these least-privilege principles at its core. In fact, one can think of EIM as *an generalized least-privilege framework not just for browser extensions, but for extensions in any software.* The way Chrome Manifest v3 limits capabilities of extensions is very much in spirit of EIM. EIM would likely provide a *declarative manifest of capabilities* for any extension: for example, a Photoshop plugin under EIM might declare it needs “open/save image file access” and nothing else – EIM would then enforce that (the plugin couldn’t suddenly access the network or registry). This is analogous to how Capsicum works at the OS level (more on Capsicum below) but applied at the application extension level.

Where current browser models focus mostly on permissions to Web APIs and sites, EIM could broaden the concept: it might include **resource sandboxing** (files, network, devices) for all extensions. Also, EIM would integrate with the sandboxing of extension code execution. Chrome and Firefox mainly ensure least privilege by controlling API access but rely on the browser’s existing sandbox to isolate extension processes. EIM would unify these – an extension under EIM gets both *a confined execution environment* (like a sandboxed process or SFI module) **and** *a restricted set of privileges*. The combination means even if the extension tries to step out of line, it’s constrained on multiple levels.

In summary, EIM extends the browser least-privilege concept to a universal model: **each extension declares capabilities, which EIM strictly enforces**, and any action outside those capabilities is blocked (or requires user consent). This addresses a gap in many current systems where enforcement might be ad-hoc or not available for all extension types. EIM’s systematic approach ensures *no extension is trusted by default* – everything is deny-by-default, allow-by-policy, which is the essence of least privilege.

### 3.2 OS-Level Security Models: Capsicum, Seccomp, and Others

The operating system provides mechanisms to confine applications, which can be repurposed to confine extensions running within applications. Two notable models are **Capsicum** (capability-based security in FreeBSD) and **seccomp** (secure computing mode in Linux). They represent the state-of-the-art in sandboxing at the OS level, and EIM’s design can learn from them or even utilize them.

- **Capsicum (FreeBSD Capabilities):** Capsicum is a lightweight OS capability and sandbox framework that brings fine-grained *capabilities* to Unix ([A Taste of Capsicum – Communications of the ACM](https://cacm.acm.org/research/a-taste-of-capsicum/#:~:text=Capsicum%20is%20an%20API%20that,0)). In Capsicum, a process can enter a *capability mode* where it can no longer access global namespaces (like opening any arbitrary file by path). Instead, it can only operate on already-opened file descriptors (which are like capabilities, with specific rights). For example, a Capsicumized application might open a needed file or socket, then drop into capability mode, and from then on it cannot open any new files that weren’t pre-opened – if it tries, the OS will deny it. This implements the least privilege principle: the app has exactly the set of resources it needs and nothing more ([[PDF] The Capsicum Security Framework: Sandboxing Done the Right Way](https://people.freebsd.org/~pgj/bsdday2012/materials/02_Capsicum.pdf#:~:text=,for%20their%20normal%20operation)). Capsicum was used to compartmentalize parts of Chromium and some Unix utilities to prove its viability ([A Taste of Capsicum – Communications of the ACM](https://cacm.acm.org/research/a-taste-of-capsicum/#:~:text=Capsicum%20is%20a%20lightweight%20operating,Capsicum%20with%20other%20sandboxing%20techniques)). It basically requires some modification to applications, but it provides a strong partition: even if an attacker takes control of a Capsicum-contained process, they *cannot* directly open new files or network connections to escalate further; they’re trapped with the file descriptors they have.

- **seccomp (Linux Seccomp-bpf):** Seccomp started as a way to reduce Linux kernel attack surface by restricting syscalls. In its strict mode, a process could be limited to only `read`, `write`, `_exit`, and `sigreturn` syscalls – effectively nothing but basic I/O ([Seccomp and sandboxing [LWN.net]](https://lwn.net/Articles/332974/#:~:text=Seccomp%20solves%20this%20problem%20by,appropriately%2C%20this%20process%20would%20call)). Later, seccomp was extended with a configurable filter (seccomp-bpf) so you can choose exactly which syscalls (and even which arguments) to allow or deny. Chrome uses seccomp-bpf on Linux to sandbox its renderer and extension processes, disallowing risky syscalls (like those that open files, create sockets, etc., which renderer code should never need) ([Seccomp and sandboxing [LWN.net]](https://lwn.net/Articles/332974/#:~:text=one%20assumes%20that%2C%20by%20now%2C,sandbox%20is%20described%20this%20way)). The idea is similar to Capsicum: *drop anything not needed*. A process running under seccomp with a tight filter is in a **strict sandbox** – even if compromised, when it tries to make a forbidden syscall (for example, attempt to execve a new process or open `/etc/passwd`), the kernel will kill the process or deny the call. Seccomp is very low-overhead (it’s just a check in the syscall path) and flexible, but it needs to be configured per application. It’s typically combined with other controls (filesystem sandboxing via chroot or namespaces, etc., since seccomp itself doesn’t manage file descriptors).

- **Other OS models:** Linux capabilities (not to be confused with Capsicum’s use of the term) allow partitioning root privileges (e.g., a process can be given the capability to bind low-numbered ports but no other root power). OpenBSD’s `pledge()` and `unveil()` calls allow processes to drop rights and limit file system access paths respectively, similar in spirit to Capsicum but simpler to use. These all enforce least privilege at the OS level. For instance, `unveil()` can restrict which file paths a process can access; after calling unveil, any attempt to open a file not unveiled is blocked by the OS – very useful for plugins or extensions that should only ever touch certain directories.

**Integration with EIM:** EIM can be thought of as bringing these OS-level sandboxing ideas into the realm of application extensions seamlessly. EIM could orchestrate OS-level protections on behalf of extensions. For example, when an extension is loaded, EIM (through the host application) could *invoke seccomp or Capsicum automatically* to lock down what that extension’s code can do. Suppose we have a database application that allows extension modules: using EIM, when it loads an extension, it might create a sandboxed subprocess for it, apply a seccomp filter that disallows any networking or file access (since a DB extension might only need some in-memory computation and perhaps use a provided API to fetch data, but not open files on its own). This way, even if the extension tries, it cannot issue a dangerous syscall. Similarly, EIM could use something like Capsicum’s approach: pre-open specific resources for the extension (if needed) and then drop the rest. 

One can see EIM as an orchestrator that combines *in-app isolation (like RLBox)* with *OS isolation (like seccomp/Capsicum)* for a belt-and-suspenders approach. The current browser extension systems partly do this (Chrome’s extension processes are in an OS sandbox). But EIM would generalize it. It ensures that not only browsers but any host software uses OS security features to sandbox extensions.

**Effectiveness:** These OS models have proven effective at mitigating exploits. For instance, even if an attacker finds a bug in Chrome’s rendering engine, Chrome’s seccomp sandbox might prevent them from doing a privileged operation to fully compromise the system ([Seccomp and sandboxing [LWN.net]](https://lwn.net/Articles/332974/#:~:text=Seccomp%20solves%20this%20problem%20by,appropriately%2C%20this%20process%20would%20call)) ([Seccomp and sandboxing [LWN.net]](https://lwn.net/Articles/332974/#:~:text=Sandbox%20leverages%20the%20OS,finished%20implementation%20is%20for%20Windows)). Capsicum has shown that applications can be compartmentalized with minimal performance impact and big security wins (if one compartment is compromised, it can’t affect others it has no capability for). EIM using these means extensions would be as secure as separate processes at the OS level when needed. 

**Flexibility and Overhead:** The overhead of using Capsicum or seccomp is very low (mainly some system call checking). The challenge is in making it transparent and easy – which is what EIM would handle. The extension developer wouldn’t need to manually write seccomp filters; EIM knows, based on the extension’s declared needs, what to allow. For example, if an extension doesn’t need to write files, EIM’s policy could automatically disallow all file-system write syscalls for that extension’s process. This is analogous to Android’s manifest permissions translating into Linux DAC rules for the app. The key point: EIM would leverage such *principle-of-least-privilege enforcement at multiple layers*, something prior art pieces each do individually but EIM combines.

### 3.3 EIM’s Approach to Current Gaps

Considering all the above, where does EIM fill gaps in extension security?

- **Unified Framework:** Many of the approaches (browser manifest, seccomp, RLBox, etc.) address parts of the puzzle. EIM aims to provide a *holistic framework* that covers memory safety, runtime isolation, and permission control together. Current systems often implement one or two of these, but not all. For example, Chrome’s extensions have sandboxed processes (isolation) and a permission system (least privilege), but the code in the extension is still just JavaScript running in V8 – if V8 had a bug, an extension might still do something unintended (though the OS sandbox would limit it). EIM would additionally ensure the extension code itself is in a safe sandbox representation, so even a JS engine bug has another line of defense.

- **Generalization beyond Browsers:** Much literature focuses on browsers (because they were a major source of extension security issues). EIM generalizes lessons from browsers to *any software that supports extensions*. For instance, a text editor, a game, or an IoT platform could all allow third-party modules, and EIM would provide a standard way to sandbox them. In industry, we see ad-hoc solutions: e.g., Adobe Reader now sandboxes its PDF plugins, or Microsoft Office has started running add-ins in separate processes with web tech. EIM could provide a consistent, proven approach applicable across domains, informed by the prior art we discussed.

- **Layered Least Privilege:** EIM doesn’t just rely on one mechanism. It would implement least privilege in multiple dimensions: 
  - *Computational:* The extension code can’t exceed certain CPU or memory bounds (prevent DoS).
  - *Memory safety:* The extension can’t corrupt the host (via SFI or language safety).
  - *System interactions:* The extension can only use allowed host APIs (like browser extension APIs or app-specific services) – no arbitrary syscalls or resource access (enforced via OS sandboxing like seccomp).
  - *Data access:* The extension can only see data it’s meant to (e.g., in a web context, respect same-origin policies; in a file context, only certain directories – achieved via capabilities/unveil, etc.).
  - *Privilege separation:* If an extension needs elevated privileges for some reason, EIM could isolate that portion in a separate component (similar to how Chrome split PDF plugin into a higher-privilege process with very limited rights otherwise). In general, EIM would encourage a design where extensions run with *user-level privileges and often even less* (no direct hardware access, etc.).

- **Closing Specific Gaps:** 
  - *Supply Chain & Integrity:* One gap not yet mentioned: ensuring extension code isn’t tampered with. EIM can incorporate a signing verification (like browsers do) so only authentic code runs. This doesn’t solve runtime issues, but prevents unauthorized code injection into the extension (which is why Manifest V3 banned remote code ([Improve extension security  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/migrate/improve-security#:~:text=Remove%20remotely%20hosted%20code))). 
  - *API Misuse:* Many extension failures (like the AVG case) are not low-level exploits but logic mistakes or overly powerful APIs. EIM addresses this by *mediating extension-host interactions.* For example, if an extension wants to elevate privileges or perform an action, EIM could prompt the user or simply disallow it if not in the manifest. In essence, EIM acts as a **policy enforcement layer** at runtime, not just a static permission agreement. This dynamic aspect is something literature like “confinement of extensions” (e.g., Brewer and Nash’s Chinese Wall, or more relevantly, browser extension isolation research) suggests: monitor what extensions do, and restrict dangerous behaviors.

- **Performance & Usability:** A gap in some academic solutions is they’re too heavy or too hard to integrate (NaCl required special compile, Capsicum requires refactoring code, etc.). EIM’s contribution could be packaging these techniques in a developer-friendly way. For instance, EIM might provide an SDK or container that developers plug into their apps to get extension safety out-of-the-box, without being security experts. The end-users or sysadmins could also get a unified interface to manage extension permissions (like how browsers show extension permission prompts – EIM could offer a similar UI for any extensible app). By basing EIM on known efficient mechanisms (like WASM, seccomp, MPK), it ensures *overhead remains low* – critical for adoption. 

**Insight:** In conclusion, EIM can be viewed as the culmination of principles from prior extension security work: it employs **least privilege** (inspired by Capsicum, Chrome, Firefox), **sandboxing** (inspired by seccomp, NaCl, RLBox), and **memory safety** (inspired by language-based methods, WASM). The novelty of EIM is in how it *integrates all these into one coherent model*. It addresses current gaps by not leaving any single aspect of extension execution to chance. If a vulnerability slips through one layer (say, a zero-day in the sandbox engine), another layer (OS policy or hardware isolation) still protects the system – this layered defense is key to EIM. 

By drawing on the rich literature and existing technologies, EIM doesn’t reinvent the wheel but rather **combines wheels into a reliable vehicle** for secure extensibility. The case studies underscored the need for such defense-in-depth. Similar approaches showed how to do it with acceptable cost. And prior art in least privilege established the policies that must guide it. EIM stands on these foundations to provide a safer future for extension ecosystems, where users can enjoy added functionality without sacrificing security.

**References:**

- Microsoft Security Bulletin MS03-042 – Buffer Overflow in Troubleshooter ActiveX (2003) ([Microsoft Security Bulletin MS03-042 - Critical | Microsoft Learn](https://learn.microsoft.com/en-us/security-updates/securitybulletins/2003/ms03-042#:~:text=A%20security%20vulnerability%20exists%20in,The%20Microsoft))  
- Tavis Ormandy, *AVG Chrome Extension vulnerabilities* (2015) ([Google probes AVG Chrome widget after 9m users exposed by bugs • The Register](https://www.theregister.com/2015/12/29/avg_google_chrome_extension/#:~:text=According%20to%20Ormandy%2C%20the%20extension,hijack%20the%20victim%27s%20webmail%20inbox))  
- DarkReading, *Chrome Zero-Day Sandbox Escape (CVE-2024-4761)* ([Dangerous Google Chrome Zero-Day Allows Sandbox Escape](https://www.darkreading.com/vulnerabilities-threats/dangerous-google-chrome-zero-day-sandbox-escape#:~:text=The%20latest%20update%2C%20to%20version,via%20a%20crafted%20HTML%20page))  
- Pentera Blog, *eBPF vulnerability leads to kernel compromise* ([Understanding the Security Aspects of Linux eBPF - Pentera](https://pentera.io/blog/the-good-bad-and-compromisable-aspects-of-linux-ebpf/#:~:text=eBBF%20is%20a%20two,review%20how%20it%20is%20done))  
- Adrienne Porter Felt, *“Least Privilege for Browser Extensions”* (2010) ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Mozilla%20Firefox%20introduced%20the%20first,Once%20a%20vulnerability%20is)) ([](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b49579dc9924744d7a6a6d945f9431a1ed867848#:~:text=Firefox%20extensions,extension%20system%2C%20which%20supports%20restrictions))  
- Chrome Developer Docs – Manifest V3 Security Changes ([Improve extension security  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/migrate/improve-security#:~:text=Remove%20execution%20of%20arbitrary%20strings)) ([Improve extension security  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/migrate/improve-security#:~:text=Remove%20remotely%20hosted%20code)) and *“Stay Secure”* guidelines ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=Request%20minimal%20permissions)) ([Stay secure  |  Chrome Extensions  |  Chrome for Developers](https://developer.chrome.com/docs/extensions/develop/security-privacy/stay-secure#:~:text=This%20extension%20in%20the%20sample,https%3A%2F%2Fmalicious_website.com))  
- Mozilla Attack & Defense blog – *RLBox in Firefox 95* ([WebAssembly and Back Again: Fine-Grained Sandboxing in Firefox 95 – Attack & Defense](https://blog.mozilla.org/attack-and-defense/2021/12/06/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/#:~:text=However%2C%20the%20transformation%20places%20two,easy%20with%20a%20tainting%20layer))  
- USENIX Security ’20 – *Narayan et al., RLBox paper* ([Retrofitting Fine Grain Isolation in the Firefox Renderer | USENIX](https://www.usenix.org/conference/usenixsecurity20/presentation/narayan#:~:text=RLBox%20supports%20efficient%20sandboxing%20through,and%20the%20zlib%20decompression%20library))  
- USENIX Security ’19 – *Vahldiek-Oberwagner et al., ERIM paper* ([ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK) | USENIX](https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner#:~:text=In%20this%20paper%2C%20we%20present,at%20high%20domain%20switching%20rates))  
- LWN.net – *Seccomp and Sandboxing* (2009) ([Seccomp and sandboxing [LWN.net]](https://lwn.net/Articles/332974/#:~:text=Seccomp%20solves%20this%20problem%20by,appropriately%2C%20this%20process%20would%20call))  
- CACM – *Capsicum: Practical Capabilities for UNIX* ([A Taste of Capsicum – Communications of the ACM](https://cacm.acm.org/research/a-taste-of-capsicum/#:~:text=Capsicum%20is%20an%20API%20that,0))  
- WebAssembly Security Documentation ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=Each%20WebAssembly%20module%20executes%20within,This%20implies)) ([Security - WebAssembly](https://webassembly.org/docs/security/#:~:text=Modules%20must%20declare%20all%20accessible,from%20control%20flow%20hijacking%20attacks)).
